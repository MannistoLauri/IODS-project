# Chapter 2: Linear regression


```{r}
date()
```
## Data


First step is to read the data created during the data wrangling part. In this case it is stored on my computer.

```{r}
learningdata=read.csv("C:/Users/03196349/Work Folders/PhD opinnot/IODS/IODS-project/data/learning2014.csv")
head(learningdata)
```

Data appears to be in good order. After importing data it is possible to inspect it.

```{r}
str(learningdata)
```
There are 8 different variables (X, gender, age, attitude, deep, stra, surf and points). Data includes different variables related to learning. X is number used to identify observations. It is irrelevant for the data exploration as it is not measurement etc. Just a tool to identify different persons. Therefore it can be excluded from graphical investigation. Scaterplot matrix is a useful tool to understand different relationships between variables. Gender could be treated as dummy-varable as it is ether male of female in this data. To clarify the visuals we can use different collours on both gender. 

```{r}
library(GGally)
library(ggplot2)
p <- ggpairs(learningdata[-1], mapping = aes(alpha=0.3, col=gender), lower = list(combo = wrap("facethist", bins = 20)))
p
```

Correlation between variables can be seen in the top/right part of the graph (total and gender separately). left/bottom part of the graph shows scatter plot. Axis on th middle shows the distribution of observations. Top row is a boxplot on effect of gender to different variables. left column is histogram of variable by gender. Top left corner is histogram of genders.  There are several aspects we can observe from this one graph. 

* There are more females than males in the data set
    * Most of the test subjects are young: about 20-25 years old
        + Males are usually slightly older.
        + There is a lack of observations of middle aged men.
    * On average males have higher attitude score than women.
    * There are little to no difference in deep learning between genders.
    * The strategic and surface learning score is slightly higher on women.
    * On average there are no differences between scores, but the top scores are slightly male dominated.

* For the most parts there are low correlation between different variables. How ever there are expections:
    + Points and gender have positive correlation (0.44)
    + Surface and deep learining has negative correlation (-0.32)
        * For males correlation is high, over -0.6, where on women it is just -0.09
        
***
## Modeling


To create model we should select variables that have high correlation with explained variable (points in this case). How ever if 2 variables have high correlation with explained variable, but they are also highly correlated with each other, they should be not both used.
In this case points are correlated with attitude. Other attributes have quite low correlation, but variables stra and surf has some level correlation with points, so we add them to model as well.


```{r}

model = lm(Points ~ Attitude + stra +surf, data = learningdata)
summary(model)
```


According to the summary table, surf has extraordinary large p-value and therefore model can be simplified.

```{r}

model2 = lm(Points ~ Attitude + stra, data = learningdata)
summary(model2)

```
If we drop the surf variable form the model, we get model more simple model with higher r-squared and smaller p-value. Now the instructions of this exercise 
 advise that non significant terms should be removed. How ever the question of significance is not black and white. It is more about how much uncertainty we are ready to accept. In **model2**  variable stra has p-value if 0.089. If we use 95% confidence level, the term is ot significant (p > 0.05) but if we use 90% confidence, it is (p < 0,1). Luckily we have more tools as decide whether or not we wish to simplify the model further.  
 
```{r}

model3 = lm(Points ~ Attitude, data = learningdata)
summary(model3)
```

If we simplify the model even further we start to loose some of validity of the model as adjusted p-value starts to decrease and therefore we might not want to only have one explanatory variable and therefore we are happy with **model2**. 


We can further analyze model variables using **Bayesian Information Criterion** (BIC)

```{r}
library(flexmix)
BIC(model)
BIC(model2)
BIC(model3)
```
According to BIC the model with only attitude as predictor is the best despite lower R-squared. 


We can yet further use tools to compare different models. Command "step" drops predictors one by one until the smallest AIC value has reaches and further simplification would increase the AIC. 
```{r}
step(model)
```
Smallest AIC score is achieved with Attitude and stra as predictors (=model2), suggesting it is the best model. It probably could be argued that model2 and model3 are both valid, but i would prefer model2. So let's take a closer look on that.

```{r}
summary(model2)

```
***

## Model validication

According to summary table model intercept is 8.97. Parameter for attitude is 0.35 and for stra 0.91. So the formula for model would be 
$Points=8.97+attitude*0.35+stra*0.91$. This means that 1 unit increase in attitude, increases points 0.35 and one unit increase of stra increases the points by 0.91. If both attetude and stra is 0, model suggests that test subject recive about than 9 points. 

R-squared explains how much variation of dependent variable is explained by independent variable. .Multiple R-squared explains how much variation in dependent variable is explained by the model **variables**. 1 would mean all variation is explained by it and 0 would mean no variation is explained. Multiple $R^2$ of this model is 0.20, suggesting that 20 % of the variation is explained by the independent variables. In addition summary table provides a adjusted $R^2$. This adjustment makes it easier to compare models with different ammounts of predictorors, as higher number of predictors tend to increase $R^2$ even if increasing the number if predictors would not increase the quality of the model as predictors will explain some percent of variance - even by coincidence. 



```{r}
plot(model2, which = 1)

```

Residuals vs fitted values are used to check for un-linearity. Residuals describe the distance between observation and model. If residuals have increasing or decreasing trend, we have issues with the model. Ie. we should have used nonlinear regression instead of linear. We can also detect outliers using this plot. the average of the residuals are close to zero trough the graph and there are no clear patterns so all is good. How ever we can detect there are some outliers in the data illustrated at the lower middle part of the graph.


```{r}
plot(model2, which = 2)

```

Normal Q-Q plot sorts observations by residuals into ascending order. Majority of observations are where one would expect them to be in normally distributed data. Only the tails are a bit off from expected values. How ever as we have limited sample size I would not be too worried about that. As a conclusion: data is or is close to be normally distributed. 


```{r}
plot(model2, which = 5)

```


Residuals vs Leverage is used to find influential observations. High leverage means changes in that observations would affect the model more compared to observations with low leverage. In this case it seems there are no highly influential observations as all of them are within cook's distance (we can't even see the threshold in this zoom). We can also see that residuals do not really change as a function of a leverage, indicating yet again normal distribution and that variances of observations have no patterns. 

***